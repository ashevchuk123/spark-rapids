@Library("jenkins-shared-library")_

env.MAVEN_CENTRAL="${MAVEN_CENTRAL_COMMON}"
env.MAPR_CENTRAL="${MAPR_CENTRAL_COMMON}"
env.MAPR_RELEASES_REPO="${MAPR_RELEASES_REPO_COMMON}"
env.MAPR_SNAPSHOTS_REPO="${MAPR_SNAPSHOTS_REPO_COMMON}"
env.MAPR_MAVEN_REPO="${MAPR_SNAPSHOTS_REPO_COMMON}"

ARTIFACTORY_SERVER=''
env.REPOSITORY_NAME=''
env.GIT_REPO_URL=''
env.GIT_SHORT_COMMIT_SHA=''
env.CURRENT_BUILD_TAG=''
env.BUILD_BY_TAG=false

env.ARTIFACTORY_PATH_RPM=''
env.ARTIFACTORY_PATH_DEB=''
env.ID=''
env.MAKEFILE_ARGS=''
env.PROJECT=''
MEP_VER=''

MAKEFILE_ARG_BRANCH_NAME = "branch-1.2.3-mapr"

pipeline {
  agent none
  triggers {
    pollSCM 'H/5 * * * *'
  }
  options {
    skipDefaultCheckout()
    disableConcurrentBuilds()
    timestamps()
  }
  parameters {
    choice(name: 'BUILD_TYPE', choices: ['Dev','EBF','Release'], description: 'default - Dev. EBF and Release args you can use only in release branches')
    string(name: 'MAKEFILE_ENV_VARS', defaultValue: '', description: 'Variables you can pass to makefile (command will be: make {THIS VAR} {project-name}). Please DO NOT put component_branch_name')
    string(name: 'BUILDVER', defaultValue: '320eep', description: '')
    booleanParam(name: 'Spark Rapids Deploy', defaultValue: true, description: 'Uncheck and Jenkins will skip ./build/mvn deploy')
  }
  stages {
    stage("Setup settings and variables") {
      agent {label "redhat8"}
      steps {
        script {
          ARTIFACTORY_SERVER = Artifactory.server 'artifactory.devops.lab'
          //MAKEFILE_ARG_BRANCH_NAME will use for makefile only for release/EBF branches
          initVariables(params.BUILD_TYPE, MAKEFILE_ARG_BRANCH_NAME)
        }
      }
    }

    stage ("Main CI process") {
      parallel {
        stage("Redhat build") {
          agent { label "redhat8" }
          stages {
            stage("Checkout") {
              steps {
                script {
                  checkout scm
                }
              }
            }

            stage("Spark Rapids Deploy") {
              when {
                expression { params.'Spark Rapids Deploy' == true }
              }
              steps {
                script {
                  configFileProvider([configFile(fileId: 'maven_settings_spark_deploy', variable: 'mvn_settings')]) {
                    sh "cat ${env.mvn_settings} > settings-deploy.xml"
                  }
                  docker.image("dfdkr.mip.storage.hpecorp.net/centos8-java11-gcc8").inside (
                  "-e MAPR_MIRROR=${MAPR_MIRROR} \
                  -e MAPR_CENTRAL=${MAPR_CENTRAL} \
                  -e MAVEN_CENTRAL=${MAVEN_CENTRAL} \
                  -e MAPR_MAVEN_REPO=${MAPR_MAVEN_REPO} \
                  -e BUILD_NUMBER=${ID}.${BUILD_NUMBER} \
                  -e MAPR_RELEASES_REPO=${MAPR_RELEASES_REPO} \
                  -e MAPR_SNAPSHOTS_REPO=${MAPR_SNAPSHOTS_REPO} \
                  -e ANT_OPTS=\"-Dhttp.proxyHost=${HPE_PROXY_HOST} -Dhttp.proxyPort=${HPE_PROXY_PORT} -Dhttps.proxyHost=${HPE_PROXY_HOST} -Dhttps.proxyPort=${HPE_PROXY_PORT} -Dhttp.nonProxyHosts='${HPE_PROXY_EXCEPTIONS}'\" \
                  -e MAVEN_OPTS=\"-Dhttp.proxyHost=${HPE_PROXY_HOST} -Dhttp.proxyPort=${HPE_PROXY_PORT} -Dhttps.proxyHost=${HPE_PROXY_HOST} -Dhttps.proxyPort=${HPE_PROXY_PORT} -Dhttp.nonProxyHosts='${HPE_PROXY_EXCEPTIONS}'\" \
                  -v /root/yum-proxy.conf:/etc/yum.conf:ro \
                  -v /etc/hosts:/etc/hosts:ro \
                  -v /root/apt-proxy.conf:/etc/apt/apt.conf.d/proxy.conf:ro \
                  -v /root/.gradle/gradle.properties:/root/.gradle/gradle.properties:ro \
                  -v /etc/profile.d/proxy.sh:/etc/profile.d/proxy.sh:ro \
                  -v /etc/localtime:/etc/localtime:ro \
                  -v /root/.ssh:/root/.ssh:rw \
                  -v ${WORKSPACE}/settings-deploy.xml:/root/.m2/settings.xml:ro") {
                    sh """
                      mvn -B -Dbuildver=${params.BUILDVER} -Drat.skip=true -DskipTests deploy -DaltDeploymentRepository=mapr-snapshots::default::${MAPR_MAVEN_REPO};
                      """
                    }
                }
              }
            }

            stage("Whitesource scan") {
              steps {
                script {
                   ws.dockerScan()
                }
              }
            }


            stage("Push Whitesource reports") {
              steps {
                script {
                  withCredentials([string(credentialsId: 'wsApiKey', variable: 'wsApiKey'), string(credentialsId: 'wsUserKey', variable: 'wsUserKey')]) {
                    catchError {
                      /*Get token of product. We have to communicate with WS API only using 64-digits project's token.
                        We are sending request to API and get ALL "project+token" pairs. Then parse this information and find token for current project*/
                        productToken = ws.getWSProductToken(PROJECT)

                        //Get reports (Excel and json) from WS site and save these reports to files. Once for each format
                        ws.getWSReports(productToken)

                        //Move latest reports to the "old" folder in Artifactory
                        ws.moveOldWsReports(ARTIFACTORY_SERVER)

                        //Upload reports (Excel and json) to the Artifactory (to the latest folder)
                        ws.uploadToArtifactory(ARTIFACTORY_SERVER)
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  post {
    failure {
      script {
        postActions.failure()
      }
    }
    fixed {
      script {
        postActions.fixed()
      }
    }
    aborted {
      script {
        postActions.aborted()
      }
    }
    always {
      script {
        postActions.always()
      }
    }
  }
}